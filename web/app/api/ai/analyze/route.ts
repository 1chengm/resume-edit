import { NextResponse, NextRequest } from 'next/server'
import { generateObject } from 'ai'
import { z } from 'zod'
import { getPrompt } from '@/lib/yaml-prompts'
import { sanitizeResume } from '@/lib/sanitize'
import { ResumeAnalysisSchema } from '@/types/ai'
import { openai } from '@ai-sdk/openai'
import { deepseek } from '@ai-sdk/deepseek'
import { createClient } from '@supabase/supabase-js'
import { authenticateRequest } from '@/lib/api-auth'
import crypto from 'crypto'

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!

export async function POST(req: NextRequest) {
  try {
    // é¦–å…ˆè¿›è¡Œè®¤è¯æ£€æŸ¥
    const { user, error: authError } = await authenticateRequest(req)
    if (authError || !user) {
      return NextResponse.json({ error: authError || 'Unauthorized' }, { status: 401 })
    }

    const body = await req.json()
    const resumeContent = body.resumeContent
    const resumeId = body.resumeId
    const forceReanalyze = body.forceReanalyze || false // ç”¨æˆ·ç‚¹å‡»é‡æ–°åˆ†ææ—¶è®¾ç½®ä¸ºtrue
    
    if (!resumeContent) return NextResponse.json({ error: 'Missing resumeContent' }, { status: 400 })

    const sanitized = sanitizeResume(resumeContent)
    const hash = crypto.createHash('sha256').update(JSON.stringify(sanitized)).digest('hex')

    console.log('ğŸ” Checking for existing AI analysis...')
    
    // æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰çš„åˆ†æç»“æœï¼ˆé™¤éç”¨æˆ·å¼ºåˆ¶é‡æ–°åˆ†æï¼‰
    if (resumeId && !forceReanalyze) {
      const supabase = createClient(supabaseUrl, supabaseAnonKey, {
        global: { headers: { Authorization: req.headers.get('authorization') || '' } }
      })
      
      // æŸ¥æ‰¾æœ€è¿‘çš„åˆ†æè®°å½•
      const { data: existingAnalysis, error: fetchError } = await supabase
        .from('ai_analysis_history')
        .select('output_json, created_at, model')
        .eq('resume_id', resumeId)
        .eq('type', 'resume')
        .eq('input_hash', hash)
        .order('created_at', { ascending: false })
        .limit(1)
        .single()

      if (!fetchError && existingAnalysis) {
        console.log('âœ… Found existing AI analysis, returning cached result')
        console.log('ğŸ“Š Cached analysis from:', existingAnalysis.created_at)
        console.log('ğŸ“Š Cached model:', existingAnalysis.model)
        
        // æ·»åŠ ç¼“å­˜æ ‡è¯†ï¼Œè®©å‰ç«¯çŸ¥é“è¿™æ˜¯ç¼“å­˜ç»“æœ
        const cachedResult = {
          ...existingAnalysis.output_json,
          is_cached: true,
          cached_at: existingAnalysis.created_at,
          cached_model: existingAnalysis.model
        }
        return NextResponse.json(cachedResult)
      }
    }

    console.log('ğŸ¤– No cached analysis found or forced reanalysis, calling AI...')
    console.log('ğŸ”§ Environment:', {
      aiProvider: process.env.AI_PROVIDER,
      deepseekConfigured: !!process.env.DEEPSEEK_API_KEY,
      openaiConfigured: !!process.env.OPENAI_API_KEY
    })

    console.log('ğŸ“Š Sanitized content length:', JSON.stringify(sanitized).length, 'characters')

    const prompt = getPrompt('ai_resume_analysis_prompt')
    console.log('ğŸ“ Loaded prompt, length:', prompt.length, 'characters')
    console.log('ğŸ“ Prompt preview:', prompt.substring(0, 200) + '...')

    // Ensure prompt contains "json" for DeepSeek API
    const jsonPrompt = prompt.includes('json') ? prompt : prompt + "\n\nImportant: Please return the analysis results in valid JSON format."
    console.log('ğŸ”§ Final prompt contains "json":', jsonPrompt.includes('json'))

    console.log('ğŸ¤– Initializing AI model...')
    const model = process.env.AI_PROVIDER === 'deepseek' ? deepseek('deepseek-chat') : openai('gpt-4o-mini')
    console.log('âœ… AI model initialized:', process.env.AI_PROVIDER || 'openai')

    console.log('ğŸ¯ Calling AI generateObject...')
    const { object } = await generateObject({
      model,
      schema: ResumeAnalysisSchema as unknown as z.ZodTypeAny,
      system: jsonPrompt,
      prompt: JSON.stringify(sanitized)
    })
    
    console.log('âœ… AI analysis successful!')
    console.log('ğŸ“Š Result overview:', {
      overallScore: object.overall_score,
      contentScore: object.scores?.content_completeness,
      structureScore: object.scores?.structure,
      expressionScore: object.scores?.expression
    })

    // ä½¿ç”¨ç®€å•å®¢æˆ·ç«¯å†™å…¥æ•°æ®åº“
    if (body.resumeId) {
      const supabase = createClient(supabaseUrl, supabaseAnonKey, {
        global: { headers: { Authorization: req.headers.get('authorization') || '' } }
      })
      const hash = crypto.createHash('sha256').update(JSON.stringify(sanitized)).digest('hex')
      await supabase.from('ai_analysis_history').insert({
        resume_id: body.resumeId,
        type: 'resume',
        model: process.env.AI_PROVIDER || 'openai',
        input_hash: hash,
        output_json: object
      })
    }
    return NextResponse.json(object)
  } catch (e: unknown) {
    const message = e instanceof Error ? e.message : 'AI analysis failed'
    return NextResponse.json({ error: message }, { status: 500 })
  }
}